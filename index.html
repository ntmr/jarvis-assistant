<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>–ñ–∞—Ä–≤–∏—Å –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç</title>
  <style>
    body {
      margin: 0; padding: 0;
      background: #121212;
      color: #eee;
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      height: 100vh;
    }
    #chat {
      flex: 1;
      overflow-y: auto;
      padding: 1rem;
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    .message {
      max-width: 75%;
      padding: 10px 15px;
      border-radius: 20px;
      font-size: 16px;
      line-height: 1.3;
      user-select: none;
    }
    .assistant {
      background: #333;
      align-self: flex-start;
    }
    .user {
      background: #555;
      align-self: flex-end;
    }
    #mute-btn {
      position: fixed;
      top: 15px; right: 15px;
      background: #444;
      color: white;
      border: none;
      padding: 10px 15px;
      font-size: 14px;
      border-radius: 8px;
      cursor: pointer;
      user-select: none;
      z-index: 10;
    }
  </style>
</head>
<body>

  <button id="mute-btn">üîä –ó–≤—É–∫ –í–ö–õ</button>
  <div id="chat"></div>

  <script>
    const chat = document.getElementById('chat');
    const muteBtn = document.getElementById('mute-btn');
    let isMuted = false;
    let isListening = false;

    // –í—Å—Ç–∞–≤—å —Å—é–¥–∞ —Å–≤–æ–π API –∫–ª—é—á DeepSeek
    const apiKey = "sk-81c4558c011d4679aebbb3f8b99d9206";

    // Speech Recognition
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = 'ru-RU';
    recognition.continuous = false;
    recognition.interimResults = false;

    // –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –æ–∑–≤—É—á–∫—É –Ω–∞ iOS/Chrome (–ø–æ –∫–ª–∏–∫—É)
    document.body.addEventListener('click', () => {
      speechSynthesis.speak(new SpeechSynthesisUtterance(''));
    }, { once: true });

    muteBtn.onclick = () => {
      isMuted = !isMuted;
      muteBtn.textContent = isMuted ? "üîá –ó–≤—É–∫ –í–´–ö–õ" : "üîä –ó–≤—É–∫ –í–ö–õ";
    };

    function appendMessage(text, role) {
      const div = document.createElement('div');
      div.className = `message ${role}`;
      div.textContent = text;
      chat.appendChild(div);
      chat.scrollTop = chat.scrollHeight;
    }

    function speak(text) {
      if (isMuted) return;
      if (!text) return;
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'ru-RU';
      speechSynthesis.cancel();
      speechSynthesis.speak(utter);

      // –ü—Ä–∏ –∑–≤—É–∫–µ —Å–ª—É—à–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å –≥—Ä–æ–º–∫–∏–µ –∑–≤—É–∫–∏ ‚Äî –ø—Ä–µ–∫—Ä–∞—Ç–∏–º –æ–∑–≤—É—á–∫—É –∏ –Ω–∞—á–Ω–µ–º —Å–ª—É—à–∞—Ç—å
      utter.onstart = () => {
        isListening = false;
        recognition.abort();
      };
      utter.onend = () => {
        startListening();
      };
    }

    async function sendToAssistant(text) {
      appendMessage(text, 'user');

      try {
        const response = await fetch("https://api.deepseek.com/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: "deepseek-chat",
            messages: [
              { role: "system", content: "–¢—ã ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ö–æ—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ –¥–µ–ª—É." },
              { role: "user", content: text }
            ]
          })
        });

        if (!response.ok) {
          const err = await response.json();
          appendMessage("–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: " + (err.message || "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"), 'assistant');
          return;
        }

        const data = await response.json();
        const reply = data.choices?.[0]?.message?.content || "–Ø –Ω–µ –ø–æ–ª—É—á–∏–ª –æ—Ç–≤–µ—Ç.";
        appendMessage(reply, 'assistant');
        speak(reply);

      } catch (e) {
        appendMessage("–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä–∞.", 'assistant');
      }
    }

    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript.trim().toLowerCase();
      console.log("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: ", transcript);
      if (transcript.includes('–∫–æ—Ç')) {
        // –£–±–µ—Ä–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ "–∫–æ—Ç" –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        const cleanText = transcript.replace(/–∫–æ—Ç/gi, '').trim();
        if (cleanText) {
          sendToAssistant(cleanText);
        } else {
          appendMessage("–î–∞?", "assistant");
          speak("–î–∞?");
        }
      }
    };

    recognition.onerror = (event) => {
      console.error("Recognition error:", event.error);
      if (event.error === "not-allowed" || event.error === "service-not-allowed") {
        appendMessage("–û—à–∏–±–∫–∞: –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â—ë–Ω.", "assistant");
      }
    };

    recognition.onend = () => {
      if (!isListening) {
        recognition.start();
        isListening = true;
      }
    };

    function startListening() {
      if (isListening) return;
      try {
        recognition.start();
        isListening = true;
      } catch (e) {
        console.error("–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:", e);
      }
    }

    // –ù–∞—á–∏–Ω–∞–µ–º —Å–ª—É—à–∞—Ç—å —Å—Ä–∞–∑—É –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
    startListening();

  </script>

</body>
</html>
