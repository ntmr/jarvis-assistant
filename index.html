<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>–ñ–∞—Ä–≤–∏—Å (–∑–∞–º–µ–Ω–∏—Ç–µ "–ñ–∞—Ä–≤–∏—Å" –Ω–∞ –ª—é–±–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ)</title>
  <style>
    body {
      margin: 0; padding: 0;
      background: #121212;
      color: #eee;
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      height: 100vh;
    }
    #chat {
      flex: 1;
      overflow-y: auto;
      padding: 1rem;
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    .message {
      max-width: 75%;
      padding: 10px 15px;
      border-radius: 20px;
      font-size: 16px;
      line-height: 1.3;
      user-select: none;
    }
    .assistant {
      background: #333;
      align-self: flex-start;
    }
    .user {
      background: #555;
      align-self: flex-end;
    }
    #mute-btn {
      position: fixed;
      top: 15px; right: 15px;
      background: #444;
      color: white;
      border: none;
      padding: 10px 15px;
      font-size: 14px;
      border-radius: 8px;
      cursor: pointer;
      user-select: none;
      z-index: 10;
    }
  </style>
</head>
<body>

  <button id="mute-btn">üîä –ó–≤—É–∫ –í–ö–õ</button>
  <div id="chat"></div>

  <script>
    const chat = document.getElementById('chat');
    const muteBtn = document.getElementById('mute-btn');
    let isMuted = false;
    let isListening = false;

    // –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –∫–ª—é—á OpenAI
    const apiKey = "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";

    // –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
    const wakeWord = "–∫–æ—Ç";

    // Speech Recognition
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert("–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏");
    }
    const recognition = new SpeechRecognition();
    recognition.lang = 'ru-RU';
    recognition.continuous = false;
    recognition.interimResults = false;

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–Ω–æ–ø–∫–∏ –∑–≤—É–∫–∞
    muteBtn.onclick = () => {
      isMuted = !isMuted;
      muteBtn.textContent = isMuted ? "üîá –ó–≤—É–∫ –í–´–ö–õ" : "üîä –ó–≤—É–∫ –í–ö–õ";
      if (isMuted) {
        speechSynthesis.cancel();
      }
    };

    // –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç
    function appendMessage(text, role) {
      const div = document.createElement('div');
      div.className = `message ${role}`;
      div.textContent = text;
      chat.appendChild(div);
      chat.scrollTop = chat.scrollHeight;
    }

    // –û–∑–≤—É—á–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    function speak(text) {
      if (isMuted || !text) return;
      speechSynthesis.cancel();
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'ru-RU';
      utter.onstart = () => {
        isListening = false;
        recognition.abort();
      };
      utter.onend = () => {
        startListening();
      };
      speechSynthesis.speak(utter);
    }

    // –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ OpenAI –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    async function sendToAssistant(text) {
      appendMessage(text, 'user');

      try {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: "gpt-3.5-turbo",
            messages: [
              { role: "system", content: "–¢—ã ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ñ–∞—Ä–≤–∏—Å. –û—Ç–≤–µ—á–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø–æ –¥–µ–ª—É –∏ –∫—Ä–∞—Ç–∫–æ." },
              { role: "user", content: text }
            ],
            max_tokens: 400,
            temperature: 0.6,
          })
        });

        if (!response.ok) {
          const err = await response.json();
          appendMessage("–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: " + (err.error?.message || "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"), 'assistant');
          return;
        }

        const data = await response.json();
        const reply = data.choices?.[0]?.message?.content || "–Ø –Ω–µ –ø–æ–ª—É—á–∏–ª –æ—Ç–≤–µ—Ç.";
        appendMessage(reply, 'assistant');
        speak(reply);

      } catch (e) {
        appendMessage("–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä–∞.", 'assistant');
      }
    }

    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript.trim().toLowerCase();
      console.log("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: ", transcript);

      if (transcript.includes(wakeWord)) {
        const cleanText = transcript.replace(new RegExp(wakeWord, 'gi'), '').trim();
        if (cleanText) {
          sendToAssistant(cleanText);
        } else {
          appendMessage("–î–∞?", "assistant");
          speak("–î–∞?");
        }
      }
    };

    recognition.onerror = (event) => {
      console.error("Recognition error:", event.error);
      if (event.error === "not-allowed" || event.error === "service-not-allowed") {
        appendMessage("–û—à–∏–±–∫–∞: –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â—ë–Ω.", "assistant");
      }
    };

    recognition.onend = () => {
      if (!isListening) {
        try {
          recognition.start();
          isListening = true;
        } catch (e) {
          console.error("–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:", e);
        }
      }
    };

    function startListening() {
      if (isListening) return;
      try {
        recognition.start();
        isListening = true;
      } catch (e) {
        console.error("–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:", e);
      }
    }

    // –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞ ‚Äî —á—Ç–æ–±—ã –æ–∑–≤—É—á–∫–∞ –∑–∞—Ä–∞–±–æ—Ç–∞–ª–∞, –Ω–∞–¥–æ —Å–Ω–∞—á–∞–ª–∞ –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
    document.body.addEventListener('click', () => {
      speechSynthesis.speak(new SpeechSynthesisUtterance(''));
    }, { once: true });

    startListening();

  </script>
</body>
</html>
